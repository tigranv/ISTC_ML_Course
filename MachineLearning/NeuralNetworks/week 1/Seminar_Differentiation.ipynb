{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go from simple to complex. \n",
    "\n",
    "Consider a function $ y = f(x) $ and we want to find its derivative\n",
    "-   let $ f : \\mathbb{R} \\rightarrow \\mathbb{R} $, everyone knows what to do\n",
    "-   let $ f : \\mathbb{R}^n \\rightarrow \\mathbb{R} $\n",
    "    \n",
    "    now x is a vector $ [x_1, x_2, \\dots x_n] $. The gradient is defined as a vector of partial direvatives\n",
    "    $$ \\frac{df}{dx} = [\\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2}, \\dots, \\frac{\\partial f}{\\partial x_n} ] $$\n",
    "\n",
    "    ***Note***: there are different conventions on what shape the gradient will have (column or row), choose whatever easier for you, but keep in mind other people may prefer different convention.\n",
    "    \n",
    "    \n",
    "-   let $ \\mathbf{f} : \\mathbb{R}^n \\rightarrow \\mathbb{R}^m $\n",
    "    \n",
    "    now $x$ is a vector $ [x_1, x_2, \\dots x_n] $ *and* $y$ is a vector $ [y_1, y_2, \\dots y_n] $. The derivative is expressed by the jacobian *matrix*. \n",
    "    \n",
    "$$\n",
    "    \\frac{d\\mathbf f}{d\\mathbf x} = \\begin{bmatrix}\n",
    "    \\dfrac{\\partial \\mathbf{f}}{\\partial x_1} & \\cdots & \\dfrac{\\partial \\mathbf{f}}{\\partial x_n} \\end{bmatrix}\n",
    "= \\begin{bmatrix}\n",
    "    \\dfrac{\\partial f_1}{\\partial x_1} & \\cdots & \\dfrac{\\partial f_1}{\\partial x_n}\\\\\n",
    "    \\vdots & \\ddots & \\vdots\\\\\n",
    "    \\dfrac{\\partial f_m}{\\partial x_1} & \\cdots & \\dfrac{\\partial f_m}{\\partial x_n} \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "-   let $ \\mathbf{f} : \\mathbb{R}^{n  \\times k}  \\rightarrow \\mathbb{R}^{ m \\times p} $\n",
    "    \n",
    "    think of $x$ as of vector with $nk$ elements, $y$ as of vector with $mp$ elements, it is previous case now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain rule\n",
    "\n",
    "Let $$ L(x) = g(f(x)) $$\n",
    "\n",
    "We aim to find $\\nabla_x L$. Obvious, if $f,g: \\mathbb{R} \\rightarrow \\mathbb{R}$ using rule:  \n",
    "\n",
    "$$ \\frac{dL}{dx} = \\frac{dg}{df}\\frac{df}{dx}$$\n",
    "\n",
    "and practical formula:\n",
    "\n",
    "$$ \\left.\\frac{dL}{dx}\\right|_{x=x_0} = \\left.\\frac{dg}{df}\\right|_{u = f(x_0)} \\cdot \\left.\\frac{df}{dx}\\right|_{x=x_0} $$\n",
    "\n",
    "What's up with multidimensional case ? Barely the same. It is the sum of 1-dimentional chains.\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial x_i} = \\sum_{j = 1}^m \\frac{\\partial g}{\\partial f_j} \\frac{\\partial f_j}{\\partial x_i}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seminar practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ex.1 (dot product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$  \n",
    "y = a^Tx\\\\\n",
    "\\frac{\\partial y}{\\partial x_i} = ? \\\\\n",
    "\\frac{dy}{dx} =  ?\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ex.2 (Matrix-vector multiplication)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$  \n",
    "y = Ax , \\quad A \\in \\mathbb{R}^{M \\times N} \\\\\n",
    "\\frac{dy}{dx} = ?\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ex.3 (Matrix-Matrix multiplication)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$  \n",
    "F = AS , \\quad A \\in \\mathbb{R}^{M \\times N}, S \\in \\mathbb{R}^{N \\times K} \\\\\n",
    "\\frac{dF}{dS} = ?\n",
    "$$\n",
    "\n",
    "The result should be of shape $\\frac{dF}{dS} \\in \\mathbb{R}^{MK \\times NK}$ and let us vectorize column by column.\n",
    "\n",
    "When $K = 1$ it fallbacks to the previous example. Let's try $K = 2$ to build an intuition.\n",
    "\n",
    "Notice, that first column in $F$ does not depend on second column in $S$, and second column in $F$ does not depend on first column in $S$. And we already know what dependence (in terms of gradient) is between corresponding columns. Thus the answer is block-diagonal matrix:\n",
    "\n",
    "$$\n",
    "\\frac{dF}{dS} = ?\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ex. 4 (Chain rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example you can recognize a model! It is simple linear regression with multiple objectives. \n",
    "$$  L = || Ax - y ||_2^2 , \\quad A \\in \\mathbb{R}^{M \\times N}, x \\in \\mathbb{R}^{N}  $$ \n",
    "Let $f = Ax$. Find $\\frac{dL}{dA}$ using chain rule. \n",
    "\n",
    "- Note, that\n",
    "$$\n",
    "|| Ax - y ||_2^2 = \\sum_{i=1}^{M} (A_{i,:}x - y_i)^2 \n",
    "$$ \n",
    "so you can easily find the gradient with respect to each row (the gradient w.r.t. vector is easier, isn't it?) and then stack these gradients to obtain gradient w.r.t. matrix $A$. **But we will go the hard way** and do it straightforward using chain rule. Let $f = Ax$ \n",
    "\n",
    "$$\n",
    "L = || f - y ||_2^2 = (f-y)^T(f-y) = f^Tf - 2f^Ty + y^Ty \\\\\n",
    "\\frac{dL}{df} = ?\n",
    "$$\n",
    "\n",
    "- Now hint, look at *ex.3* last result (block-diag matrix), what if we multiply something by this matrix ? In fact, suppose we vectorized a given matrix $B$ into vector $B_{vec}$ of size $N^2$ and we multiply a block-diagonal matrix of size $N^2 \\times N^2$ with $C$ on diagonal by $B_{vec}$. The resulting vector $D_{vec}$ has $N^2$ elements but if reshaped is exactly $D = CB^T$. This can look idiosyncratic for the first time but it is easy.\n",
    "\n",
    "- So what we should learn from the example above? That $\\frac{df}{dA}$ is something block-diagonal-like with $x$ on diagonal and the resulting $\\frac{dL}{dA}$ is just a multiplication of $\\frac{dL}{df}$ and $x$ (transpose something to get correct dimentions). Finally, \n",
    "\n",
    "$$\n",
    "\\frac{df}{dA} = ?\n",
    "$$\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
