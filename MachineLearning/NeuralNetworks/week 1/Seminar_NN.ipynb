{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Deep Learning</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## Score function\n",
    "Linear regressor, SVM, Neural Network ...\n",
    "* ## Loss function\n",
    "L2/MeanSquared loss, L1 loss, CrossEntropy loss ...\n",
    "* ## Optimization\n",
    "SGD, Nesterov Momentum, Adam ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tr>\n",
    "<td> <img src=\"img/neuron.png\" style=\"height: 250px;\"/> </td>\n",
    "<td> <img src=\"img/neuron_model.jpeg\" style=\"height: 250px;\"/> </td>\n",
    "</tr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate number of parameters.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tr>\n",
    "<td> <img src=\"img/neural_net.jpeg\" style=\"height: 250px;\"/> </td>\n",
    "<td> <img src=\"img/neural_net2.jpeg\" style=\"height: 250px;\"/> </td>\n",
    "</tr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.linspace(-10, 10), 1/(1+np.exp(-np.linspace(-10, 10))));plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\large \\sigma(x)=\\frac{1}{1+e^{-x}}$\n",
    "<br>\n",
    "It takes a real-valued number and “squashes” it into range between 0 and 1. In particular, large negative numbers become 0 and large positive numbers become 1. The sigmoid function has seen frequent use historically since it has a nice interpretation as the firing rate of a neuron: from not firing at all (0) to fully-saturated firing at an assumed maximum frequency (1). In practice, the sigmoid non-linearity has recently fallen out of favor and it is rarely ever used. It has two major drawbacks:\n",
    "\n",
    "1. Sigmoids saturate and kill gradients. Note that $\\sigma'(x) = \\sigma(x) (1-\\sigma(x))$. When the neuron’s activation saturates at either tail of 0 or 1, the gradient at these regions is almost zero. Recall that during backpropagation, this (local) gradient will be multiplied to the gradient of this gate’s output for the whole objective. Therefore, if the local gradient is very small, it will effectively “kill” the gradient and almost no signal will flow through the neuron to its weights and recursively to its data. Additionally, one must pay extra caution when initializing the weights of sigmoid neurons to prevent saturation. For example, if the initial weights are too large then most neurons would become saturated and the network will barely learn.\n",
    "2. Sigmoid outputs are not zero-centered. If the data coming into a neuron is always positive (e.g. $x>0$ elementwise in $f=w^Tx+b$)), then the gradient on the weights w will during backpropagation become either all be positive, or all negative (depending on the gradient of the whole expression $f$). This could introduce undesirable zig-zagging dynamics in the gradient updates. However, notice that once these gradients are added up across a batch of data the final update for the weights can have variable signs, somewhat mitigating this issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.linspace(-10, 10), np.tanh(np.linspace(-10, 10)));plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the tanh neuron is a scaled sigmoid neuron:\n",
    "<br>\n",
    "$\\large tanh(x)=\\frac{e^x - e^{-x}}{e^x + e^{-x}} = 2\\sigma(2x)-1$\n",
    "<br>\n",
    "It squashes a real-valued number to the range [-1, 1]. Like the sigmoid neuron, its activations saturate, but unlike the sigmoid neuron its output is zero-centered. Therefore, in practice the tanh non-linearity is always preferred to the sigmoid nonlinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.linspace(-10, 10), np.maximum(np.linspace(-10, 10), 0));plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Rectified Linear Unit. It computes the function $f(x)=max(0,x)$. In other words, the activation is simply thresholded at zero. There are several pros and cons to using the ReLUs:\n",
    "\n",
    "* (+) It was found to greatly accelerate the convergence of stochastic gradient descent compared to the sigmoid/tanh functions. It is argued that this is due to its linear, non-saturating form.\n",
    "* (+) Compared to tanh/sigmoid neurons that involve expensive operations (exponentials, etc.), the ReLU can be implemented by simply thresholding a matrix of activations at zero.\n",
    "* (-) Unfortunately, ReLU units can be fragile during training and can “die”. For example, a large gradient flowing through a ReLU neuron could cause the weights to update in such a way that the neuron will never activate on any datapoint again. If this happens, then the gradient flowing through the unit will forever be zero from that point on. That is, the ReLU units can irreversibly die during training since they can get knocked off the data manifold. For example, you may find that as much as 40% of your network can be “dead” (i.e. neurons that never activate across the entire training dataset) if the learning rate is set too high. With a proper setting of the learning rate this is less frequently an issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression\n",
    "* L2 norm squared loss\n",
    "<br>\n",
    "$L_i = \\Vert f - y_i \\Vert_2^2$\n",
    "<br>\n",
    "The reason the L2 norm is squared in the objective is that the gradient becomes much simpler, without changing the optimal parameters since squaring is a monotonic operation. \n",
    "* L1 norm loss is sum of the absolute values along each dimension:\n",
    "$L_i = \\Vert f - y_i \\Vert_1 = \\sum_j \\mid f_j - (y_i)_j \\mid$\n",
    "\n",
    "[Differences between L1 and L2 as Loss Function and Regularization](http://www.chioka.in/differences-between-l1-and-l2-as-loss-function-and-regularization/)\n",
    "\n",
    "Question: What is the difference (calculate $\\partial{L_i} / \\partial{f_j}$ gradient)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification\n",
    "We assume tere is a single correct label (out of a fixed set) for each example. **Cross-entropy loss**:\n",
    "<br>\n",
    "$\\large L_i = -\\log\\left(\\frac{e^{f_{y_i}}}{ \\sum_j e^{f_j} }\\right)$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attribute classification\n",
    "$y_i$ is a binary vector: 1 - sample have certain attribute, 0 - sample do not have certain attribute. Maximum likelihood loss function is:\n",
    "<br>\n",
    "$\\large L_i = \\sum_j y_{ij} \\log(\\sigma(f_j)) + (1 - y_{ij}) \\log(1 - \\sigma(f_j))$\n",
    "<br>\n",
    "where the labels $y_{ij}$ are assumed to be either 1 (positive) or 0 (negative), and $\\sigma(⋅)$ is the sigmoid function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGD (stochastic gradient descent)\n",
    "The simplest form of update is to change the parameters along the negative gradient direction.\n",
    "```python\n",
    "# SGD update\n",
    "x += - learning_rate * dx\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tr>\n",
    "<td> <img src='img/sgdvsgd.png' width=\"400px\"> </td>\n",
    "<td> <img src=\"img/gradient.jpg\" height=\"400px\"/> </td>\n",
    "</tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient descent with momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach almost always enjoys better converge rates on deep networks. This update can be motivated from a physical perspective of the optimization problem. Initializing the parameters with random numbers is equivalent to setting a particle with zero initial velocity at some location. The optimization process can then be seen as equivalent to the process of simulating the particle as rolling on the landscape.\n",
    "\n",
    "Since the force on the particle is related to the gradient of potential energy (i.e. $F = - \\nabla U$ ), the force felt by the particle is precisely the (negative) gradient of the loss function. Moreover, $F=ma$ so the (negative) gradient is in this view proportional to the acceleration of the particle. Note that this is different from the SGD update shown above, where the gradient directly integrates the position. Instead, the physics view suggests an update in which the gradient only directly influences the velocity, which in turn has an effect on the position:\n",
    "```python\n",
    "# Momentum update\n",
    "v = mu * v - learning_rate * dx # integrate velocity\n",
    "x += v # integrate position\n",
    "```\n",
    "Here we see an introduction of a v variable that is initialized at zero, and an additional hyperparameter (mu) which is called momentum (its typical value is about 0.9), but its physical meaning is more consistent with the coefficient of friction. Effectively, this variable damps the velocity or otherwise the particle would never come to a stop at the bottom of a hill. When cross-validated, this parameter is usually set to values such as [0.5, 0.9, 0.95, 0.99]. Similar to annealing schedules for learning rates (discussed later, below), optimization can sometimes benefit a little from momentum schedules, where the momentum is increased in later stages of learning. A typical setting is to start with momentum of about 0.5 and anneal it to 0.99 or so over multiple epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nesterov Momentum\n",
    "This is a slightly different version of the momentum update that has recently been gaining popularity. It enjoys stronger theoretical converge guarantees for convex functions and in practice it also consistenly works slightly better than standard momentum.\n",
    "![nesterov](img/nesterov.jpeg)\n",
    "```python\n",
    "x_ahead = x + mu * v\n",
    "# evaluate dx_ahead (the gradient at x_ahead instead of at x)\n",
    "v = mu * v - learning_rate * dx_ahead\n",
    "x += v\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annealing the learning rate\n",
    "In training deep networks, it is usually helpful to anneal the learning rate over time. Good intuition to have in mind is that with a high learning rate, the system contains too much kinetic energy and the parameter vector bounces around chaotically, unable to settle down into deeper, but narrower parts of the loss function. Knowing when to decay the learning rate can be tricky: Decay it slowly and you’ll be wasting computation bouncing around chaotically with little improvement for a long time. But decay it too aggressively and the system will cool too quickly, unable to reach the best position it can. There are three common types of implementing the learning rate decay:\n",
    "\n",
    "* **Step decay**: Reduce the learning rate by some factor every few epochs. Typical values might be reducing the learning rate by a half every 5 epochs, or by 0.1 every 20 epochs. These numbers depend heavily on the type of problem and the model. One heuristic you may see in practice is to watch the validation error while training with a fixed learning rate, and reduce the learning rate by a constant (e.g. 0.5) whenever the validation error stops improving.\n",
    "* **Exponential decay**. has the mathematical form $\\alpha = \\alpha_0 e^{-k t}$, where $\\alpha_0, k$ are hyperparameters and t is the iteration number (but you can also use units of epochs).\n",
    "* **1/t decay** has the mathematical form $\\alpha = \\alpha_0 / (1 + k t )$ where $\\alpha_0, k$ are hyperparameters and t is the iteration number.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adam is a method for efficient stochastic optimization that only requires first-order gradients with little memory requirement. The method computes **individual adaptive learning rates for different parameters** from estimates of first and second moments of the gradients; the name Adam is derived from adaptive moment estimation. Some of Adam’s advantages are that the magnitudes of parameter updates are **invariant** to rescaling of the gradient, its stepsizes are approximately bounded by the stepsize hyperparameter, it does not require a stationary objective, it works with sparse gradients, and it naturally performs a form of step size annealing.\n",
    "<br>\n",
    "[Paper](https://arxiv.org/pdf/1412.6980.pdf)\n",
    "\n",
    "![adam](img/adam.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differnet optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tr>\n",
    "<td> <img src=\"img/optimizers.gif\" /> </td>\n",
    "<td> <img src=\"img/optimizers2.gif\" /> </td>\n",
    "</tr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Mean subtraction** is the most common form of preprocessing. It involves subtracting the mean across every individual feature in the data, and has the geometric interpretation of centering the cloud of data around the origin along every dimension.\n",
    "\n",
    "* **Normalization** refers to normalizing the data dimensions so that they are of approximately the same scale. There are two common ways of achieving this normalization. One is to divide each dimension by its standard deviation, once it has been zero-centered. Another form of this preprocessing normalizes each dimension so that the min and max along the dimension is -1 and 1 respectively. \n",
    "It only makes sense to apply this preprocessing if you have a reason to believe that different input features have different scales (or units), but they should be of approximately equal importance to the learning algorithm.\n",
    "\n",
    "![preprocessing](img/preprocessing.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L2 regularization \n",
    "L2 regularization penalizes the squared magnitude of all parameters directly in the objective. That is, for every weight $w$ in the network, we add the term $\\frac{1}{2} \\lambda w^2$ to the objective, where $\\lambda$ is the regularization strength. The L2 regularization has the intuitive interpretation of heavily penalizing peaky weight vectors and preferring diffuse weight vectors. Note that during gradient descent parameter update, using the L2 regularization ultimately means that every weight is decayed linearly: $W \\mathrel{+}= -\\lambda  W$ towards zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L1 regularization\n",
    "For each weight $w$ we add the term $\\lambda|w|$ to the objective. It is possible to combine the L1 regularization with the L2 regularization: $\\lambda_1 ∣w∣+\\lambda_2 w^2$ (this is called Elastic net regularization). The L1 regularization has the intriguing property that it leads the weight vectors to become sparse during optimization (i.e. very close to exactly zero). In other words, neurons with L1 regularization end up using only a sparse subset of their most important inputs and become nearly invariant to the “noisy” inputs. In comparison, final weight vectors from L2 regularization are usually diffuse, small numbers. In practice, if you are not concerned with explicit feature selection, L2 regularization can be expected to give superior performance over L1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout\n",
    "Dropout is an extremely effective, simple and recently introduced regularization technique. While training, dropout is implemented by only keeping a neuron active with some probability p (a hyperparameter), or setting it to zero otherwise. [Paper](http://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf)\n",
    "![dropout](img/dropout.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch normalization\n",
    "We normalize the input layer by adjusting and scaling the activations. For example, when we have features from 0 to 1 and some from 1 to 1000, we should normalize them to speed up learning. If the input layer is benefiting from it, why not do the same thing also for the values in the hidden layers, that are changing all the time, and get 10 times or more improvement in the training speed.\n",
    "\n",
    "To increase the stability of a neural network, batch normalization normalizes the output of a previous activation layer by subtracting the batch mean and dividing by the batch standard deviation.\n",
    "<br>\n",
    "After this shift/scale of activation outputs by some randomly initialized parameters, the weights in the next layer are no longer optimal. SGD ( Stochastic gradient descent) undoes this normalization if it’s a way for it to minimize the loss function.\n",
    "<br>\n",
    "Consequently, batch normalization adds two trainable parameters to each layer, so the normalized output is multiplied by a “standard deviation” parameter (gamma) and add a “mean” parameter (beta). In other words, batch normalization lets SGD do the denormalization by changing only these two weights for each activation, instead of losing the stability of the network by changing all the weights.\n",
    "<br>\n",
    "![batchnorm](img/batchnorm.png)\n",
    "* We can use higher learning rates because batch normalization makes sure that there’s no activation that’s gone really high or really low.\n",
    "* It reduces overfitting because it has a slight regularization effects. Similar to dropout, it adds some noise to each hidden layer’s activations. Therefore, if we use batch normalization, we will use less dropout, which is a good thing because we are not going to lose a lot of information and computational power. However, we should not depend only on batch normalization for regularization; we should better use it together with dropout.\n",
    "\n",
    "[Paper](https://arxiv.org/pdf/1502.03167.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
