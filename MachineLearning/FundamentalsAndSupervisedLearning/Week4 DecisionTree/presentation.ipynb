{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecisionTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example for split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### entropy and gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22c414acac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22c3fb2a550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22c43543e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22c4354e630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22c45cdb6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22c4513bdd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib \n",
    "matplotlib.rcParams.update({'font.size': 22})\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import math\n",
    "\n",
    "iris = load_iris()\n",
    "for pairidx, pair in enumerate([[0, 1], [0, 2], [0, 3],\n",
    "                                [1, 2], [1, 3], [2, 3]]):\n",
    "    X = iris.data[:, pair]\n",
    "    y = iris.target\n",
    "\n",
    "    clf = DecisionTreeClassifier(criterion=\"gini\").fit(X, y)\n",
    "\n",
    "    plt.figure(figsize=(16,9))\n",
    "    plt.subplot()\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
    "                     np.arange(y_min, y_max, 0.02))\n",
    "    plt.tight_layout(h_pad=0.5, w_pad=0.5, pad=2.5)\n",
    "\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    cs = plt.contourf(xx, yy, Z, cmap=plt.cm.RdYlBu)\n",
    "    plt.xlabel(iris.feature_names[pair[0]])\n",
    "    plt.ylabel(iris.feature_names[pair[1]])\n",
    "    \n",
    "    for i, color in zip(range(3), \"ryb\"):\n",
    "        idx = np.where(y == i)\n",
    "        plt.scatter(X[idx, 0], X[idx, 1], c=color, label=iris.target_names[i],\n",
    "                    cmap=plt.cm.RdYlBu, edgecolor='black', s=130)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "iris = load_iris()\n",
    "clf = tree.DecisionTreeClassifier(criterion=\"gini\")\n",
    "clf = clf.fit(iris.data, iris.target)\n",
    "\n",
    "# import graphviz \n",
    "# dot_data = tree.export_graphviz(clf, out_file=None) \n",
    "# graph = graphviz.Source(dot_data) \n",
    "# # graph.render(\"iris\") \n",
    "# dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "#                          feature_names=iris.feature_names,  \n",
    "#                          class_names=iris.target_names,  \n",
    "#                          filled=True, rounded=True,  \n",
    "#                          special_characters=True) \n",
    "# graph = graphviz.Source(dot_data) \n",
    "# graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_of_values(data):\n",
    "    # TODO Calculate the number of each label.\n",
    "    # Return a dict with the labels as keys, and\n",
    "    # their accurances as values\n",
    "    unique, counts = np.unique(data[:, -1], return_counts=True)\n",
    "    return dict(zip(unique, counts))\n",
    "\n",
    "def divide_data(data, feature_column, feature_val):\n",
    "    data1 = data[data[:, feature_column] < feature_val]\n",
    "    data2 = data[data[:, feature_column] > feature_val]\n",
    "    # TODO split the data into two parts by feature_column,\n",
    "    # where data1 contains all with value at feature column less than\n",
    "    # feature_value, and data2 contains all values larger that veature_val \n",
    "    return data1, data2\n",
    "\n",
    "def gini(data):\n",
    "    gini = 1\n",
    "    total_count = float(len(data))\n",
    "    #TODO calculate the gini\n",
    "    counts = dict_of_values(data)\n",
    "    for lbl in counts:\n",
    "        prob_of_lbl = counts[lbl] / total_count\n",
    "        gini -= prob_of_lbl**2\n",
    "    return gini\n",
    "\n",
    "\n",
    "# def info_gain(data):\n",
    "#     entropy_dict = {}\n",
    "#     for col in range(list(data.shape)[1] -1):\n",
    "#         data_entropy = entropy(data)\n",
    "#         unique, counts = np.unique(data[:, col], return_counts=True)\n",
    "#         for i in range(len(unique)):\n",
    "#             data_entropy -= (counts[i]/float(len(data))) * entropy(data[data[:, col] == unique[i]])\n",
    "#         entropy_dict[col] = data_entropy\n",
    "   \n",
    "#     print(entropy_dict)\n",
    "#     return entropy_dict\n",
    "\n",
    "\n",
    "def entropy(data):\n",
    "    entropy = 0\n",
    "    total_count = float(len(data))\n",
    "    counts = dict_of_values(data)\n",
    "    for lbl in counts:\n",
    "        prob_of_lbl = counts[lbl] / total_count\n",
    "        entropy += -prob_of_lbl*math.log(prob_of_lbl, 2)\n",
    "    #TODO calculate the entropy\n",
    "    return entropy\n",
    "\n",
    "def square_loss(data):\n",
    "    loss = 0\n",
    "    total_count = float(len(data))\n",
    "    mean_y = np.mean(data[:, -1])\n",
    "    for y in data[:, -1]:\n",
    "        loss += (y - mean_y)**2\n",
    "    #TODO calculate the entropy\n",
    "    return loss/total_count\n",
    "\n",
    "class DecisionNode(object):\n",
    "    def __init__(self,\n",
    "                 column=None,\n",
    "                 value=None,\n",
    "                 false_branch=None,\n",
    "                 true_branch=None,\n",
    "                 current_results=None,\n",
    "                 is_leaf=False):\n",
    "        \"\"\"\n",
    "        node of each split\n",
    "        column is the index of feature by wich data is splitted\n",
    "        value is column's value by which we filter data into splits\n",
    "        if true_branch, then it is true branch of it's parent, same for fale_branch\n",
    "        is_leaf is true when node has no child\n",
    "        current_Results is dict_of_values(data) for data which reached this node\n",
    "        \"\"\"\n",
    "        \n",
    "        self.column = column\n",
    "        self.value = value\n",
    "        self.false_branch = false_branch\n",
    "        self.true_branch = true_branch\n",
    "        self.current_results = current_results\n",
    "        self.is_leaf = is_leaf\n",
    "\n",
    "def build_tree(data, current_depth=0, max_depth=4, criterion=gini, task=\"classification\"):\n",
    "    \"\"\"\n",
    "    task can be classification or regression\n",
    "    criterion is inpurity function to use\n",
    "    \"\"\"\n",
    "\n",
    "    if len(data) == 0:\n",
    "        return DecisionNode(is_leaf=True)\n",
    "\n",
    "    if current_depth == max_depth:\n",
    "        return DecisionNode(current_results=dict_of_values(data), is_leaf=True)\n",
    "    \n",
    "    if len(dict_of_values(data)) == 1:\n",
    "        return DecisionNode(current_results=dict_of_values(data), is_leaf=True)\n",
    "\n",
    "    \n",
    "    best_column = 0\n",
    "    best_value = 0\n",
    "    stop_splitting = False\n",
    "\n",
    "    \n",
    "    criterion_parent = criterion(data)*len(data)\n",
    "    best_criterion = criterion_parent\n",
    "\n",
    "    \n",
    "    for col in range(list(data.shape)[1] -1):\n",
    "        min_val = min(data[:,col])\n",
    "        max_val = max(data[:,col])\n",
    "        step = 0.1 #(max_val - min_val) * 0.1\n",
    "        for s_val in np.arange(min_val + step, max_val + step, step):\n",
    "            d1, d2 = divide_data(data, col, s_val)\n",
    "            best_criterion_1_2 = len(d1)*criterion(d1) + len(d2)*criterion(d2)\n",
    "            if best_criterion_1_2 < best_criterion:\n",
    "                best_criterion = best_criterion_1_2\n",
    "                best_column = col\n",
    "                best_value = s_val\n",
    "            \n",
    "    if best_criterion == criterion_parent:\n",
    "            stop_splitting = True      \n",
    "    \n",
    "\n",
    "    split_neg, split_pos = divide_data(data, best_column, best_value)\n",
    "    \n",
    "    # if we cannot improve by splitting:\n",
    "    if stop_splitting:\n",
    "        return DecisionNode(current_results=dict_of_values(data), is_leaf=True)\n",
    "    else:\n",
    "        return DecisionNode(column=best_column,\n",
    "                            value=best_value,\n",
    "                            current_results=dict_of_values(data),\n",
    "                            false_branch=build_tree(split_neg, current_depth+1, max_depth, criterion, task),\n",
    "                            true_branch=build_tree(split_pos, current_depth+1, max_depth, criterion, task))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree(object):\n",
    "    \n",
    "    def __init__(self, max_tree_depth=4, criterion=\"gini\", task=\"classification\"):\n",
    "        self.max_depth = max_tree_depth\n",
    "        self.tree = None\n",
    "        self.task = task\n",
    "        \n",
    "        self.criterion = gini\n",
    "        if criterion == \"entropy\":\n",
    "            self.criterion = entropy\n",
    "        if criterion == \"square_loss\":\n",
    "            self.criterion = square_loss\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # build data\n",
    "        y = y.reshape((1, X.shape[0]))\n",
    "        data = np.hstack((X, y.T))\n",
    "        self.tree = build_tree(data,\n",
    "                               task=self.task,\n",
    "                               max_depth=self.max_depth, \n",
    "                               criterion=self.criterion)\n",
    "        return self\n",
    "    \n",
    "  \n",
    "    def predict_sample(self, tree, sample):\n",
    "        if sample[tree.column] < tree.value:\n",
    "\n",
    "            if  not tree.false_branch.is_leaf:\n",
    "                return self.predict_sample(tree.false_branch, sample)\n",
    "            else:\n",
    "                return tree.false_branch\n",
    "        else:\n",
    "            if  not tree.true_branch.is_leaf:\n",
    "                return self.predict_sample(tree.true_branch,sample)\n",
    "            else:\n",
    "                return tree.true_branch\n",
    "            \n",
    "            \n",
    "    def predict(self, X_test):\n",
    "        self.y_pred = np.array([])\n",
    "        for i in X_test:\n",
    "            dn = self.predict_sample(self.tree, i)\n",
    "            d = dn.current_results\n",
    "            if self.task == \"classification\":\n",
    "                pred = max(d, key=d.get)\n",
    "            if self.task == \"regression\":\n",
    "                pred = mean(sum(d.values()))\n",
    "            self.y_pred = np.append(self.y_pred, pred)\n",
    "        return self.y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hmm, something is wrong :[\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tigran PC\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\Tigran PC\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    iris = load_iris()\n",
    "    for pairidx, pair in enumerate([[0, 1], [0, 2], [0, 3], [1, 2], [1, 3], [2, 3]]):\n",
    "        X = iris.data[:, pair]\n",
    "        y = iris.target\n",
    "\n",
    "        clf = DecisionTree(criterion=\"square_loss\", task=\"regression\").fit(X, y)\n",
    "\n",
    "        plt.figure(figsize=(8,4.5))\n",
    "        plt.subplot()\n",
    "        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "        xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
    "                         np.arange(y_min, y_max, 0.02))\n",
    "        plt.tight_layout(h_pad=0.5, w_pad=0.5, pad=2.5)\n",
    "\n",
    "        Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "        Z = Z.reshape(xx.shape)\n",
    "\n",
    "        cs = plt.contourf(xx, yy, Z, cmap=plt.cm.RdYlBu)\n",
    "        plt.xlabel(iris.feature_names[pair[0]])\n",
    "        plt.ylabel(iris.feature_names[pair[1]])\n",
    "\n",
    "        for i, color in zip(range(3), \"ryb\"):\n",
    "            idx = np.where(y == i)\n",
    "            plt.scatter(X[idx, 0], X[idx, 1], c=color, label=iris.target_names[i],\n",
    "                        cmap=plt.cm.RdYlBu, edgecolor='black', s=130)\n",
    "    plt.show()\n",
    "except:\n",
    "    print(\"Hmm, something is wrong :[\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.584962500721156"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "\n",
    "X = iris.data[:, [0, 1]]\n",
    "y = iris.target\n",
    "y = y.reshape((1, X.shape[0]))\n",
    "\n",
    "data = np.hstack((X, y.T))\n",
    "\n",
    "entropy(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
