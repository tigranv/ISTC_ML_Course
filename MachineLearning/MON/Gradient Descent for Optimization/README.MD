# Purpose
The jupyter notebook "Gradient Descent for Optimization.ipynb" implements gradient descent from scratch and approximates the global minimum of single and multiple variable functions. The notebook contains the mathematical details of the Gradient descent and shows implementation in python. This notebook does not rely on real data but instead focuses on understanding the algorithm as a tool to find minimums of a differentiable function. 

# References
[Siraj's video on Evolution of Gradient Descent](https://www.youtube.com/watch?v=nhqo0u1a6fw&t=334s)

[Gradient Descent Introduction](https://www.analyticsvidhya.com/blog/2017/03/introduction-to-gradient-descent-algorithm-along-its-variants/)

[Another Gradient Descent Introduction](http://www.big-data.tips/gradient-descent)

[Gradient Descent for Regression](https://spin.atomicobject.com/2014/06/24/gradient-descent-linear-regression/)

