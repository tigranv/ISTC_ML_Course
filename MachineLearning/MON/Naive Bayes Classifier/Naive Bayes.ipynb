{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes for Spam Classification\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Naive bayes is a relatively simple probabilistic classfication algorithm that is well suitable for categorical data (probabilities can be compuated as simple ratios) and uses the bayes theorem together with a strong (hence \"naive\") independence assumption. The basic idea behind Naive Bayes is that it assigns a probability to every category (finite outcome variable) based on the features in the data and chooses the outcome that is most likely as its prediction.\n",
    "\n",
    "The \"Naive\" in the name refers to the algorithm assuming features in the data are independent conditional on the outcome category. For example suppose we were doing spam text classification, then given a spam text \"Free, sign up now!\", Naive Bayes would assume \"Free\", \"sign\", \"up, \"now\" all occur indepedently of each other (that is $Pr(Free, sign, up, now|spam)$ = $Pr(Free|spam)\\times Pr(sign|spam)\\times Pr(up|spam) \\times Pr(now|spam)$). This conditional independence assumption is considered to be a strong assumption that often doesn't hold in practice, hence the resulting probabilities from Naive Bayes are not to be taken too seriously. However the classifications resulting from Naive Bayes can still be accurate. \n",
    "\n",
    "In machine learning, common application of Naive Bayes are spam email classification, sentiment analysis, document categorization. Naive bayes is advantageous over other commonly used classification algorithms in its simplicity, speed, and its accuracy on small data sets. Since Naive Bayes needs to be trained on a labeled data set it considered to a supervisd learning algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing Bayes Theorem\n",
    "\n",
    "Consider two events, $A$ and $B$. For example $A$ could be a set of words found in many emails, and $B$ could be a set that has two categories, spam or ham (legitimate email). Then we might be interested in computing the $Pr(A = FREE|B = spam)$, which is the probability of a spam email containing the word \"FREE\". In general, let us try to come up with a formula for the conditional $Pr(A|B).$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAyAAAAEsCAYAAAA7Ldc6AABTsklEQVR42u2dC9AV5X3/Ey+taW2D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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(filename='vendiagram.png', embed=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure above on the left illustrates a ven diagram of the sample space U (U is for \"universe\"), event A, and event B. For example in a die roll, $U = \\{1,2,3,4,5,6\\},$ $A$ = Roll even number, $B$ = roll 4 or 6. By definition we have $Pr(U) = 1,$ but suppose we know event $B$ has occured, that takes us to the right figure. Now B is the new sample space (because we know we are in B), and are interested in computing the probability of also being in $A$ at the same time. This mean we find to the probability of being in $A$ and $B$ given that we are in $B$, this the red shaded region on the right figure above. It's easy to see from the right figure that $$Pr(A|B) = \\frac{\\text{Area of A and B}}{\\text{Area of B}} = \\frac{Pr(A \\text{ and } B)}{Pr(B)}.$$ Note that we can have similar argument for finding $$Pr(B|A) = \\frac{\\text{Area of A and B}}{\\text{Area of A}} = \\frac{Pr(A \\text{ and } B)}{Pr(A)}.$$\n",
    "\n",
    "From the above argument we have shown that $P(A \\text{ and } B) = P(A|B)P(B) = P(B|A)P(A),$ and hence now we can compute $$Pr(A|B) = \\frac{P(B|A)P(B)}{P(A)},$$ this is the Bayes theorem. The $Pr(B)$ is known as the \"prior probability\", for example the prior probabiling of a coin landing on heads could be $0.5.$ Whereas the $Pr(B|A)$ is often known as the \"likelihood\", this is a measure of how much we trust our result $B$ given $A$. Finally $Pr(A)$ is the \"marginal\" probability of $A$. Essentially the bayes rule is a realatively easy formula for finding conditional probabilities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formulating Naive Bayes\n",
    "\n",
    "Suppose we have a data set where each observation $i$ belongs to a category from the finite set $C_{i} = \\{c_{1i},c_{2i},\\ldots, c_{ki}\\},$ and consists of several features $W_{i} = \\{w_{1i},\\ldots,w_{mi}\\}.$ If we could find probabilities $Pr(c_{1i}|W_{i}), Pr(c_{2i}|W_{i}), \\ldots, Pr(c_{ki}|W_{i}),$ then we could predict the label for observation $i$ to be the one that has the highest probability. \n",
    "\n",
    "To compute conditional probabilities, we can use the Bayes theorem from statistics which says, $$Pr(c_{ji}|W_{i}) = \\frac{Pr(c_{ji} \\text{ and } W_{i})}{Pr(W_{i})} = \\frac{Pr(W_{i}|c_{ji})Pr(c_{ji})}{Pr(W_{i})},$$ where $j = 1, 2, \\ldots, k.$ Usually $Pr(W_{i})$ and $Pr(c_{ji})$ are either well known, or can be estimated easily from the data. However $Pr(W_{i}|c_{ji})$ is a another conditional probability that we need to find and using Bayes rule again will not help here. This is were the \"Naive\" part steps in, we assume that the data features $w_{1i}, w_{2i}, \\ldots, w_{mi}$ are all independent of each other conditional on knowing the class $c_{ji}.$ Statistically that means $$Pr(W_{i}|c_{ji}) = Pr(w_{1i}, w_{2i}, \\ldots, w_{mi}|c_{ji}) = Pr(w_{1i}|c_{ji})Pr(w_{2i}|c_{ji}) \\ldots Pr(w_{mi}|c_{ji}).$$ Given this result from the \"Naive\" assumption of conditional indepdence, we can compute $$Pr(c_{ji}|W_{i}) = \\frac{Pr(W_{i}|c_{ji})Pr(c_{ji})}{Pr(W_{i})} = \\frac{Pr(w_{1i}|c_{ji})Pr(w_{2i}|c_{ji}) \\ldots Pr(w_{mi}|c_{ji})Pr(c_{ji})}{Pr(W_{i})}.$$ \n",
    "\n",
    "In many problems we can find $Pr(w_{li}|c_{ji})$ for $l = 1,\\ldots,m$ by using $$Pr(w_{li}|c_{ji}) = \\frac{Pr(w_{li} \\text{ and } c_{ji})}{Pr(c_{ji})}.$$ Therefore we can find the probability of each class occuring given features in the data, $Pr(c_{1i}|W_{i}),Pr(c_{2i}|W_{i}), \\ldots, Pr(c_{ki}|W_{i}).$ Next we can just compare all of these probabilities to each other, and pick the class that is most likely. Also note that we can omit $Pr(W_{i})$ in the denominator above because it is common to all the conditional class probabilities and will not effect their rankings, that is if $$\\frac{Pr(w_{1i}|c_{1i}) \\ldots Pr(w_{mi}|c_{1i})Pr(c_{1i})}{Pr(W_{i})} > \\frac{Pr(w_{1i}|c_{2i}) \\ldots Pr(w_{mi}|c_{2i})Pr(c_{2i})}{Pr(W_{i})} \\implies $$ $$Pr(w_{1i}|c_{1i}) \\ldots Pr(w_{mi}|c_{1i})Pr(c_{1i}) > Pr(w_{1i}|c_{2i}) \\ldots Pr(w_{mi}|c_{2i})Pr(c_{2i}). $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Description\n",
    "\n",
    "We will be using a data from the UCI machine learning repository that countains several Youtube comments from very popular music videos. Each comment in the data has been labeled as either spam or ham (legitimate comment), we will use this data to train our Naive Bayes algorithm for youtube comment spam classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "# For data manipulation\n",
    "import pandas as pd\n",
    "# For matrix operations\n",
    "import numpy as np\n",
    "# For numerical division\n",
    "from __future__ import division\n",
    "# For regular expression (text cleaning)\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>+447935454150 lovely girl talk to me xxx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I always end up coming back to this song&lt;br /&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my sister just received over 6,500 new &lt;a rel=...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cool</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hello I am from Palastine</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  label\n",
       "0           +447935454150 lovely girl talk to me xxx      1\n",
       "1     I always end up coming back to this song<br />      0\n",
       "2  my sister just received over 6,500 new <a rel=...      1\n",
       "3                                               Cool      0\n",
       "4                          Hello I am from Palastine      1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data set and display a few observations\n",
    "data_comments = pd.read_csv('YoutubeComments.csv')\n",
    "\n",
    "# Create column labels\n",
    "data_comments.columns = [\"content\",\"label\"]\n",
    "data_comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only have two variables in our data, the youtube comment and its label of being spam or legitimate. We already know that a legitimate comment would be one relating to the video itself, let's get a sense of what spam comments look like. $\\textbf{WARNING: Please DO NOT go on the links in the spam comments below as they might be unsafe.}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                +447935454150 lovely girl talk to me xxx\n",
      "2       my sister just received over 6,500 new <a rel=...\n",
      "4                               Hello I am from Palastine\n",
      "6       Go check out my rapping video called Four Whee...\n",
      "8                           Aslamu Lykum... From Pakistan\n",
      "10                            Help me get 50 subs please \n",
      "12      Alright ladies, if you like this song, then ch...\n",
      "15      <a href=\"https://www.facebook.com/groups/10087...\n",
      "16                  Take a look at this video on YouTube:\n",
      "17                 Check out our Channel for nice Beats!!\n",
      "19                    Check out this playlist on YouTube:\n",
      "21                                            like please\n",
      "24      I shared my first song &quot;I Want You&quot;,...\n",
      "25      Come and check out my music!Im spamming on loa...\n",
      "26                    Check out this playlist on YouTube:\n",
      "27      HUH HYUCK HYUCK IM SPECIAL WHO S WATCHING THIS...\n",
      "30      Check out this video on YouTube:<br /><br />Lo...\n",
      "33                    Check out this playlist on YouTube:\n",
      "34                       Check out this video on YouTube:\n",
      "35                       Check out this video on YouTube:\n",
      "38      Check out this playlist on YouTube:chcfcvzfzfb...\n",
      "39                   Check out this playlist on YouTube: \n",
      "40      Im gonna share a little ryhme canibus blows em...\n",
      "41                       Check out this video on YouTube:\n",
      "42      Check out this video on YouTube<br /><br /><br />\n",
      "43        CHECK OUT THE NEW REMIX !!!<br />CLICK CLICK !!\n",
      "44                    Check out this playlist on YouTube:\n",
      "45      I personally have never been in a abusive rela...\n",
      "48                                  plese subscribe to me\n",
      "49                       Check out this video on YouTube:\n",
      "                              ...                        \n",
      "1915             CHECK OUT partyman318 FR GOOD TUNEZ!! :D\n",
      "1916    Hey youtubers... I really appreciate all of yo...\n",
      "1917    Hey Music Fans I really appreciate any of you ...\n",
      "1918    Hey Music Fans I really appreciate any of you ...\n",
      "1919    Hey Music Fans I really appreciate any of you ...\n",
      "1920                   Hi. Check out and share our songs.\n",
      "1921                   Hi. Check out and share our songs.\n",
      "1922                    Hi.Check out and share our songs.\n",
      "1923    Hey Music Fans I really appreciate any of you ...\n",
      "1924    Hey, I am doing the Forty Hour famine so I ll ...\n",
      "1925             Love itt and ppl check out my channel!!!\n",
      "1926                                 SUBSCRIBE MY CHANNEL\n",
      "1927                                       adf.ly / KlD3Y\n",
      "1928                                       adf.ly / KlD3Y\n",
      "1929                               check out my new video\n",
      "1930    Hey Music Fans I really appreciate all of you ...\n",
      "1931    Hello everyone, It Is not my intention to spam...\n",
      "1932    ******* Facebook is LAME and so 2004! Check ou...\n",
      "1933    Please check out and send to others Freedom an...\n",
      "1934    Nice to meet You - this is Johnny: 1. If You a...\n",
      "1935     hey you ! check out the channel of Alvar Lake !!\n",
      "1936    Hi -this is Johnny: 1. If You already know my ...\n",
      "1940    Check out this video on YouTube:<br />&quot;Th...\n",
      "1942    O peoples of the earth, I have seen how you pe...\n",
      "1945    I WILL NEVER FORGET THIS SONG IN MY LIFE LIKE ...\n",
      "1946    ********OMG Facebook is OLD! Check out  ------...\n",
      "1947    Hey Music Fans I really appreciate all of you ...\n",
      "1948    **CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY ...\n",
      "1949    **CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY ...\n",
      "1950    **CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY ...\n",
      "Name: content, Length: 1004, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Show spam comments in data\n",
    "# DO NOT GO ON THE LINKS BELOW!!!\n",
    "print data_comments[\"content\"][data_comments[\"label\"] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Browsing over the comments that have been labeled as spam in this data, it seems like these comments are either unrelated to the video, or are some form of advertisement. The phrase \"check out\" seems to be very popular in this comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics and Data Cleaning\n",
    "\n",
    "The table below shows that this data set consist of $1959$ youtube comments, about $49\\%$ of them are legitimate comments and about $51\\%$ are spam. This high variation of classes in our data set will help us test our algorithms accuracy on the test data set. The average length of each comment is about $96$ characters, which is roughly about $15$ words on average per comment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1959.000000</td>\n",
       "      <td>1959.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.512506</td>\n",
       "      <td>96.734558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.499971</td>\n",
       "      <td>137.319807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>98.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1717.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             label       length\n",
       "count  1959.000000  1959.000000\n",
       "mean      0.512506    96.734558\n",
       "std       0.499971   137.319807\n",
       "min       0.000000     2.000000\n",
       "25%       0.000000    29.000000\n",
       "50%       1.000000    48.000000\n",
       "75%       1.000000    98.500000\n",
       "max       1.000000  1717.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add another column with corresponding comment length\n",
    "data_comments['length'] = data_comments['content'].map(lambda text: len(text))\n",
    "\n",
    "# Summary statistics (mean, stdev, min, max)\n",
    "data_comments[[\"label\",\"length\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of evaluation our Naive Bayes classification algorithm, we will split the data into a training and test set. The training set will be used to train the spam classification algorithm, and the test set will only be used to test its accuracy. In general the training set should be bigger than the test set and both have should be drawn from the same population (population in our case is youtube comments for music videos). We will randomly select $75\\%$ of the data as training, and $25\\%$ of the data for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1485.000000\n",
       "mean        0.509764\n",
       "std         0.500073\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         1.000000\n",
       "75%         1.000000\n",
       "max         1.000000\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's split data into training and test set (75% training, 25% test)\n",
    "\n",
    "# Set seed so we get same random allocation on each run of code\n",
    "np.random.seed(2017)\n",
    "\n",
    "# Add column vector of randomly generated numbers form U[0,1]\n",
    "data_comments[\"uniform\"] = np.random.uniform(0,1,len(data_comments.index)) \n",
    "\n",
    "# About 75% of these numbers should be less than 0.75\n",
    "data_comments_train = data_comments[data_comments[\"uniform\"] < 0.75]\n",
    "\n",
    "# About 25% of these numbers should be more than 0.75\n",
    "data_comments_test = data_comments[data_comments[\"uniform\"] > 0.75]\n",
    "\n",
    "# Check that both training and test data have both spam and ham comments\n",
    "data_comments_train[\"label\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    474.000000\n",
       "mean       0.521097\n",
       "std        0.500083\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        1.000000\n",
       "75%        1.000000\n",
       "max        1.000000\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test data summary statistics\n",
    "data_comments_test[\"label\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the training and test data have a good mix spam and ham comments, so we are ready to move onto training the Naive Bayes classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words in training data: 5898\n",
      "First 5 words in our unique set of words: \n",
      " ['now!!!!!!', 'yellow', 'four', '/>.Pewdiepie', 'Does']\n"
     ]
    }
   ],
   "source": [
    "# Join all the comments into a big list\n",
    "training_list_words = \"\".join(data_comments_train.iloc[:,0].values)\n",
    "\n",
    "# Split the list of comments into a list of unique words\n",
    "train_unique_words = set(training_list_words.split(' '))\n",
    "\n",
    "# Number of unique words in training \n",
    "vocab_size_train = len(train_unique_words)\n",
    "\n",
    "# Description of summarized comments in training data\n",
    "print('Unique words in training data: %s' % vocab_size_train)\n",
    "print('First 5 words in our unique set of words: \\n % s' % list(train_unique_words)[1:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently \"now!!\" and \"now!!!!\", as well as \"DOES\",\"DoEs\", and \"does\" are all considered to be unique words. For the purposes of spam classification, its probably better to process the data slightly to increase accuracy. In our case we can focus on letters and numbers, as well as convert all the comments to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words in processed training data: 4129\n",
      "First 5 words in our processed unique set of words: \n",
      " ['jaesuk', 'partwierd', 'vanossbest', 'storyhttpshhortcomarhupweh5abyay', 'personally']\n"
     ]
    }
   ],
   "source": [
    "# Only keep letters and numbers\n",
    "train_unique_words = [re.sub(r'[^a-zA-Z0-9]','', words) for words in train_unique_words]\n",
    "\n",
    "# Convert to lower case and get unique set of words\n",
    "train_unique_words = set([words.lower() for words in train_unique_words])\n",
    "\n",
    "# Number of unique words in training \n",
    "vocab_size_train = len(train_unique_words)\n",
    "\n",
    "# Description of summarized comments in training data\n",
    "print('Unique words in processed training data: %s' % vocab_size_train)\n",
    "print('First 5 words in our processed unique set of words: \\n % s' % list(train_unique_words)[1:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes for Spam Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reffering to the Naive Bayes formulation above, in the context of comment spam classification, now $i$ is a index for the comment, the classes $C_{i} = \\{1 = Spam, 0 = Ham\\},$ and features of comments are the words in it, $W_{i}$. For example if the $ith$ comment as \"Check out my chanell!\", then  $W_{i} = \\{Check, out, my, chanell!\\}.$ If we wanted to classify this comment using naive bayes, we need to compute $$Pr(Spam|\\{Check, out, my, chanell!\\}) \\propto Pr(Check|Spam) \\ldots Pr(chanell!|Spam)Pr(Spam),$$ and, $$Pr(Ham|\\{Check, out, my, chanell!\\}) \\propto Pr(Check|Ham) \\ldots Pr(chanell!|Ham)Pr(Ham),$$ \n",
    "note that the proportional symbol is used above since we are omitting $Pr(\\{Check, out, my, chanell!\\})$ in the denominator. \n",
    "\n",
    "Firstly, to find $Pr(Spam)$ and $Pr(Ham)$, we can just compute the proportion of spam and ham emails in our training data respectively. To find the probability of say \"Check\" appearing in spam emails, we can just compute the proportion of times \"Check\" appears in a spam email. That is, $$Pr(Check|Spam) = \\frac{Pr(\\text{Check and Spam})}{Pr(Spam)} = \\frac{\\text{Number of times \"Check\" appers in spam comments}}{\\text{Number of total words in spam comments + Number of unique words in data}}.$$ We can similarly compute $Pr(Check|Ham)$ and also do this with any other word in the comment. Training in Naive Bayes just means we are going to be computing a bunch of conditional probabilities, $Pr(\\text{word in comment}|\\text{comment label}).$ Therefore classification in Naive Bayes is simple as if $$Pr(Spam|Comment) > Pr(Ham|Comment) \\implies \\text{Comment is spam},$$ and if $$Pr(Spam|Comment) < Pr(Ham|Comment) \\implies \\text{Comment is ham}.$$ \n",
    "\n",
    "Given that we calculuate these conditonal probabilities using the words in our training data, what happens when a comment contains words in the training data? The $Pr(\\text{Word not in training data}|Spam) = 0,$ which will imply $Pr(Spam|\\text{Comment with word not in training data}) = 0.$ This is a problem because any spam email with a word not in training data will not be assigned as spam. To resolve this, we compute $$Pr(\\text{word in comment}|Spam) = \\frac{\\alpha+\\text{Number of times word appears in spam comments}}{\\text{Number of total words in spam comments + Number of unique words in data}},$$ where $alpha > 0$ is known as the laplace smoothing parameter. If we say $\\alpha = 1,$ then a $Pr(\\text{Word not in training data}|Spam)$ will be a small positive number instead of $0.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dictionary with comment words as \"keys\", and their label as \"value\"\n",
    "trainPositive = dict()\n",
    "trainNegative = dict()\n",
    "\n",
    "# Intiailize classes\n",
    "positiveTotal = 0\n",
    "negativeTotal = 0\n",
    "\n",
    "# Initialize Prob. of\n",
    "pSpam = 0.0\n",
    "pNotSpam = 0.0\n",
    "\n",
    "# Laplace smoothing\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def initialize_dicts():\n",
    "\n",
    "# Initialize dictionary of words and their labels   \n",
    "for word in train_unique_words:\n",
    "    \n",
    "    # Classify all words for now as ham (legitimate)\n",
    "    trainPositive[word] = 0\n",
    "    trainNegative[word] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Count number of times word in comment appear in spam and ham comments\n",
    "def processComment(comment,label):\n",
    "    global positiveTotal\n",
    "    global negativeTotal\n",
    "    \n",
    "    # Split comments into words\n",
    "    comment = comment.split(' ')\n",
    "    \n",
    "    # Go over each word in comment\n",
    "    for word in comment:\n",
    "        \n",
    "        # ham commments\n",
    "        if(label == 0 and word != ' '):\n",
    "            \n",
    "            # Increment number of times word appears in ham comments\n",
    "            trainNegative[word] = trainNegative.get(word,0)+1\n",
    "            negativeTotal += 1\n",
    "            \n",
    "        # spam comments\n",
    "        elif(label == 1 and word != ' '):\n",
    "            \n",
    "            # Increment number of times word appears in spam comments\n",
    "            trainPositive[word] = trainPositive.get(word,0)+1\n",
    "            positiveTotal += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Prob(word|spam) and Prob(word|ham)\n",
    "def conditionalWord(word,label):\n",
    "    \n",
    "    # Laplace smoothing parameter\n",
    "    global alpha\n",
    "    \n",
    "    # word in ham comment\n",
    "    if(label == 0):\n",
    "        # Compute Prob(word|ham)\n",
    "        return (trainNegative.get(word,0)+alpha)/(float)(negativeTotal+alpha*vocab_size_train)\n",
    "    \n",
    "    # word in spam comment\n",
    "    else:\n",
    "        \n",
    "        # Compute Prob(word|ham)\n",
    "        return (trainPositive.get(word,0)+alpha)/(float)(positiveTotal+alpha*vocab_size_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Prob(spam|comment) or Prob(ham|comment)\n",
    "def conditionalComment(comment,label):\n",
    "    \n",
    "    # Initialize conditional probability\n",
    "    prob_label_comment = 1.0\n",
    "    \n",
    "    # Split comments into list of words\n",
    "    comment = comment.split(' ')\n",
    "    \n",
    "    # Go through all words in comments\n",
    "    for word in comment:\n",
    "        \n",
    "        # Compute value proportional to Prob(label|comment)\n",
    "        # Conditional indepdence is assumed here\n",
    "        prob_label_comment *= conditionalWord(word,label)\n",
    "    \n",
    "    return prob_label_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train naive bayes by computing several conditional probabilities in training data\n",
    "def train():\n",
    "    \n",
    "    print('Starting training')\n",
    "    global pSpam\n",
    "    global pNotSpam\n",
    "\n",
    "    # Initiailize \n",
    "    total = 0\n",
    "    numNegative = 0\n",
    "    \n",
    "    # Go over each comment in training data\n",
    "    for idx, comment in data_comments_train.iterrows():\n",
    "        \n",
    "        # Comment is ham \n",
    "        if comment.label == 0:\n",
    "            \n",
    "            # Increment ham comment counter\n",
    "            numNegative += 1\n",
    "        \n",
    "        # Increment comment number\n",
    "        total += 1\n",
    "        \n",
    "        # Update dictionary of ham and spam comments\n",
    "        processComment(comment.content,comment.label)\n",
    "    \n",
    "    # Compute prior probabilities, P(spam), P(ham)\n",
    "    pSpam = numNegative/float(total)\n",
    "    pNotSpam = (total - numNegative)/float(total)\n",
    "    \n",
    "    print('Training is now finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "Training is now finished\n"
     ]
    }
   ],
   "source": [
    "# Run naive bayes\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Classify comment are spam or ham\n",
    "def classify(comment):\n",
    "    \n",
    "    global pSpam\n",
    "    global pNotSpam\n",
    "    \n",
    "    # Compute value proportional to Pr(comment|ham)\n",
    "    isNegative = pSpam * conditionalComment(comment,0)\n",
    "    \n",
    "    # Compute value proportional to Pr(comment|spam)\n",
    "    isPositive = pNotSpam * conditionalComment(comment,1)\n",
    "    \n",
    "    # Output True = spam, False = ham\n",
    "    return (isNegative < isPositive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of comments classified correctly on test set: 0.816455696203\n"
     ]
    }
   ],
   "source": [
    "# Initialize spam prediction in test data\n",
    "prediction_test = []\n",
    "\n",
    "# Get prediction accuracy on test data\n",
    "for comment in data_comments_test[\"content\"]:\n",
    "\n",
    "    # Classify comment \n",
    "    prediction_test.append(classify(comment))\n",
    "\n",
    "# Check accuracy\n",
    "test_accuracy = np.mean(np.equal(prediction_test, data_comments_test[\"label\"]))\n",
    "\n",
    "#print prediction_test\n",
    "print(\"Proportion of comments classified correctly on test set: %s\" % test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me try writing some comments to see whether they are classified as spam or ham. Recall the \"True\" is for spam comments, and \"False\" is for ham comments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spam\n",
    "classify(\"Guys check out my new chanell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spam\n",
    "classify(\"I have solved P vs. NP, check my video https://www.youtube.com/watch?v=dQw4w9WgXcQ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ham\n",
    "classify(\"I liked the video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ham\n",
    "classify(\"Its great that this video has so many views\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending Bag of Words by Using TF-IDF\n",
    "So far we have been using the Bag of Words model to represent comments as vectors. The \"Bag of Words\" is a list of all unique words found in the training data, then each comment can be represented by a vector that contains the frequency of each unique word that appeared in the comment. For example if the training data contains the words $(hi, how, my, grade, are, you),$ then the text \"how are you you\" can be represented by $(0,1,0,0,1,2).$ The main reason we do this in our application is because comments can vary in length, but the length of all unique words stays fixed. \n",
    "\n",
    "In our context, the TF-IDF is a measure of how important a word is in a comment relative to all the words in our training data. For example if a word such as \"the\" appeared in most of the comments, the TF-IDF would be small as this word does not help us differentiate accross comments. Note that \"TF\" stands for \"Term Frequency\", and \"IDF\" stands for \"Inverse Document Frequency\". In particular, \"TF\" denoted by $tf(w,c)$ is the number of times the word $w$ appears in the given comment $c$. Whereas \"IDF\" is a measure of how much information a given word provides in differentiating comments. Specefically, $IDF$ is formulated as $idf(w, D) = log(\\frac{\\text{Number of comments in train data $D$}}{\\text{Number of comments containing the word $w$}}).$ To combine \"TF\" and \"IDF\" together, we simple take the product, hence $$TFIDF = tf(w,c) \\times idf(w, D) = (\\text{Number of times $w$ appears in comment $c$})\\times log(\\frac{\\text{Number of comments in train data $D$}}{\\text{Number of comments containing the word $w$}}).$$\n",
    "Now the $TF-IDF$ can be used to weight the vectors that result from the \"Bag of Words\" approach. For example, suppose a comment contains \"this\" 2 times, hence $tf = 2$. If we then had 1000 comments in our traininig data, and the word \"this\" appears in 100 comments, $idf = log(1000/100) = 2.$ Therefore in this example, the TF-IDF weight would be 2*2 = 4 for the word \"this\" appear twice in a particular comment. To incorprate TF-IDF into the naive bayes setting, we can compute $$Pr(word|spam) = \\frac{\\sum_{\\text{c is spam}}TFIDF(word,c,D)}{\\sum_{\\text{word in spam c}}\\sum_{\\text{c is spam}}TFIDF(word,c,D)+ \\text{Number of unique words in data}},$$ where $TFIDF(word,c,D) = TF(word,c) \\times IDF(word,data).$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute tfidf(word, comment, data)\n",
    "def TFIDF(comment, train):\n",
    "    \n",
    "    # Split comment into list of words\n",
    "    comment = comment.split(' ')\n",
    "    \n",
    "    # Initiailize tfidf for given comment\n",
    "    tfidf_comment = np.zeros(len(comment))\n",
    "    \n",
    "    # Initiailize number of comments containing a word\n",
    "    num_comment_word = 0\n",
    "    \n",
    "    # Intialize index for words in comment\n",
    "    word_index = 0\n",
    "    \n",
    "    # Go over all words in comment\n",
    "    for word in comment:\n",
    "        \n",
    "        # Compute term frequence (tf)\n",
    "        # Count frequency of word in comment\n",
    "        tf = comment.count(word)\n",
    "        \n",
    "        # Find number of comments containing word\n",
    "        for text in train[\"content\"]:\n",
    "            \n",
    "            # Increment word counter if word found in comment\n",
    "            if text.split(' ').count(word) > 0:\n",
    "                num_comment_word += 1\n",
    "        \n",
    "        # Compute inverse document frequency (idf)\n",
    "        # log(Total number of comments/number of comments with word)\n",
    "        idf = np.log(len(train.index)/num_comment_word)\n",
    "        \n",
    "        # Update tf-idf weight for word\n",
    "        tfidf_comment[word_index] = tf*idf\n",
    "        \n",
    "        # Reset comment containing word counter\n",
    "        num_comment_word = 0\n",
    "        \n",
    "        # Move onto next word in comment\n",
    "        word_index += 1\n",
    "        \n",
    "    return tfidf_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.06142304,  1.54111867,  1.84784894,  3.63960841,  3.17603567,\n",
       "        2.04047986,  5.3572599 ])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFIDF(\"Check out my new music video plz\",data_comments_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we introduced the Bayes rule and how it is used by the Naive Bayes algorithm for text classification. Using Naive Bayes with bag of words for youtube comment spam classification resulted in about $82 \\%$ accuracy on the training data. Since the model is trained on youtube music videos comments, it may not be very accurate in classifying spam and ham comments for other videos. $\\textbf{TFIDF is in progress, add in accuracy once complete}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
